import torch
import torch.optim as optim
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import os
import sys

current_dir = os.path.dirname(os.path.abspath(__file__))
core_path = os.path.join(current_dir, "core")
if core_path not in sys.path: sys.path.insert(0, core_path)

# ==============================================================================
# æ¨¡å‹å®šä¹‰ (å¿…é¡»ä¸ train_sim.py / finetune_real.py å®Œå…¨ä¸€è‡´)
# ==============================================================================
class CausalTransformer(nn.Module):
    def __init__(self, input_dim, output_dim, embed_dim=64, num_layers=2, num_heads=4, history_len=10):
        super().__init__()
        self.embedding = nn.Linear(input_dim, embed_dim)
        self.pos_embed = nn.Parameter(torch.zeros(1, history_len, embed_dim))
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim*4,
            batch_first=True, dropout=0.0, activation='relu'
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.head = nn.Linear(embed_dim, output_dim)

    def forward(self, x):
        B, T, D = x.shape
        emb = self.embedding(x) + self.pos_embed[:, :T, :]
        mask = torch.triu(torch.ones(T, T) * float('-inf'), diagonal=1).to(x.device)
        feat = self.transformer(emb, mask=mask)
        # è¿”å› [Batch, Output_Dim] (2D Tensor)
        return self.head(feat[:, -1, :])

def run_mpc():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"=== Running Differentiable MPC on {device} ===")
    
    # 1. åŠ è½½æ¨¡å‹
    model_path = "nerd_sim_weights.pth" 
    if os.path.exists("nerd_real_final.pth"):
        print("ğŸ’¡ å‘ç°å¾®è°ƒåçš„æ¨¡å‹ï¼Œä½¿ç”¨å®ç‰©æ¨¡å‹ï¼")
        model_path = "nerd_real_final.pth"
    else:
        print("âš ï¸ æœªæ‰¾åˆ°å¾®è°ƒæ¨¡å‹ï¼Œä½¿ç”¨ Sim æ¨¡å‹")
        
    if not os.path.exists("nerd_stats.pt"):
        print("âŒ ç¼ºå°‘ nerd_stats.ptï¼Œæ— æ³•è¿›è¡Œå½’ä¸€åŒ–")
        return

    # åŠ è½½ç»Ÿè®¡é‡
    stats = torch.load("nerd_stats.pt", map_location=device)
    
    # åˆå§‹åŒ–æ¨¡å‹ (ç¡®ä¿å‚æ•°ä¸è®­ç»ƒæ—¶ä¸€è‡´: layers=2, embed=64)
    model = CausalTransformer(
        input_dim=7, output_dim=4, embed_dim=64, num_layers=2, history_len=10
    ).to(device)
    
    try:
        model.load_state_dict(torch.load(model_path))
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
        
    model.eval()
    
    # å†»ç»“å‚æ•°
    for param in model.parameters():
        param.requires_grad = False

    # 2. å®šä¹‰æ§åˆ¶ä»»åŠ¡
    target_pos = 1.5 
    horizon = 50 
    h = 10 
    
    # åˆå§‹çŠ¶æ€ (é™æ­¢)
    # [1, h, 1]
    curr_q = torch.zeros(1, h, 1, device=device)
    curr_qd = torch.zeros(1, h, 1, device=device)
    curr_action = torch.zeros(1, h, 1, device=device)
    
    # 3. å¾…ä¼˜åŒ–çš„æ§åˆ¶åºåˆ—
    # åˆå§‹åŒ–ä¸ºä¸€ä¸ªå°çš„éšæœºå€¼æˆ–è€…0
    future_actions = torch.zeros(1, horizon, 1, device=device, requires_grad=True)
    
    # å­¦ä¹ ç‡å¯ä»¥å¤§ä¸€ç‚¹ï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯åœ¨ä¼˜åŒ– Inputï¼Œä¸æ˜¯ Weights
    optimizer = optim.Adam([future_actions], lr=0.5)
    
    print(f"ğŸ¯ ç›®æ ‡: ç§»åŠ¨åˆ° {target_pos} rad")
    
    # MPC ä¼˜åŒ–å¾ªç¯
    for step in range(300):
        optimizer.zero_grad()
        loss = 0
        
        # æ¨¡æ‹Ÿæœªæ¥ (Rollout)
        sim_q = curr_q.clone()
        sim_qd = curr_qd.clone()
        sim_action = curr_action.clone()
        
        predicted_traj = []
        
        for t in range(horizon):
            # A. æ„é€ è¾“å…¥ç‰¹å¾ [1, h, 6]
            feat = torch.cat([
                torch.sin(sim_q), torch.cos(sim_q), 
                torch.sin(sim_q), torch.cos(sim_q), # Copy Heuristic for Load
                sim_qd, sim_qd
            ], dim=-1)
            
            # B. å½’ä¸€åŒ–
            s_norm = (feat - stats['s_mean']) / stats['s_std']
            
            # åŠ¨ä½œçª—å£å¤„ç†
            act_t = future_actions[:, t:t+1, :] # [1, 1, 1]
            
            # æ‹¼æ¥åŠ¨ä½œå†å²: å– [old_action[1:], new_action]
            next_action_window = torch.cat([sim_action[:, 1:], act_t], dim=1)
            a_norm = (next_action_window - stats['a_mean']) / stats['a_std']
            
            # C. æ¨¡å‹é¢„æµ‹
            model_in = torch.cat([s_norm, a_norm], dim=-1) # [1, h, 7]
            
            # ã€å…³é”®ä¿®å¤ã€‘æ¨¡å‹è¿”å› [1, 4] (2D)ï¼Œæˆ‘ä»¬éœ€è¦å‡ç»´æˆ [1, 1, 4] (3D)
            # è¿™æ ·æ‰èƒ½å’Œåé¢çš„åˆ‡ç‰‡è¿ç®—åŒ¹é…
            pred_delta_norm = model(model_in).unsqueeze(1) 
            
            # D. åå½’ä¸€åŒ–
            pred_delta = pred_delta_norm * stats['d_std'] + stats['d_mean']
            
            # E. ç§¯åˆ† (Next State = Current Last + Delta)
            # Delta 0: Motor Pos, Delta 2: Motor Vel
            next_q = sim_q[:, -1:, :] + pred_delta[:, :, 0:1]
            next_qd = sim_qd[:, -1:, :] + pred_delta[:, :, 2:3]
            
            # F. æ›´æ–°æ»‘åŠ¨çª—å£
            sim_q = torch.cat([sim_q[:, 1:], next_q], dim=1)
            sim_qd = torch.cat([sim_qd[:, 1:], next_qd], dim=1)
            sim_action = next_action_window
            
            # è®°å½•è½¨è¿¹
            predicted_traj.append(next_q)
            
            # --- Loss è®¡ç®— ---
            # 1. ä½ç½®è¯¯å·® (æƒé‡æœ€å¤§)
            loss += (next_q - target_pos) ** 2 * 20.0
            
            # 2. é€Ÿåº¦æƒ©ç½š (å¸Œæœ›ç»ˆç‚¹é™æ­¢)
            if t > horizon - 10:
                loss += (next_qd) ** 2 * 2.0
            
            # 3. åŠ¨ä½œèƒ½é‡æƒ©ç½š (çœç”µ/å¹³æ»‘)
            loss += (act_t) ** 2 * 0.001
            
        loss.backward()
        optimizer.step()
        
        if step % 10 == 0:
            print(f"Iter {step}: Loss = {loss.item():.4f}")

    # 4. ç»˜å›¾
    actions_np = future_actions.detach().cpu().numpy().flatten()
    traj_np = torch.cat(predicted_traj, dim=1).detach().cpu().numpy().flatten()
    
    plt.figure(figsize=(10, 8))
    
    plt.subplot(2, 1, 1)
    plt.plot(traj_np, 'r-', label='MPC Plan', lw=2)
    plt.axhline(y=target_pos, color='g', ls='--', label='Target')
    plt.title("Planned Trajectory")
    plt.ylabel("Position (rad)")
    plt.grid(True)
    plt.legend()
    
    plt.subplot(2, 1, 2)
    plt.plot(actions_np, 'b-', label='Torque', lw=2)
    plt.title("Optimized Control Sequence")
    plt.ylabel("Torque (Nm)")
    plt.xlabel("Time Step (0.01s)")
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig("mpc_result.png")
    print("âœ… MPC è§„åˆ’å®Œæˆï¼æŸ¥çœ‹ mpc_result.png")

if __name__ == "__main__":
    run_mpc()